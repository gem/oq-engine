#!/usr/bin/python
# -*- coding: utf-8 -*-
# vim: tabstop=4 shiftwidth=4 softtabstop=4

"""Deterministic Risk Computations based on Hazard, Exposure and Vulnerability

Expects to receive:
    Shakemap (ground motion per grid cell)
    Exposure (value per grid cell)
    Vulnerability functions (multiple lists per grid cell)
    Region of interest

It can receive these either through gflags (current functionality), or
through a configuration file.

Expects to compute:
    A grid of loss-ratio curves and store the results in XML
    A grid of loss curves and store the results in XML 
    A map of losses at each interval and store the results in GeoTIFF

"""

import os
import sys

# this is a hack so that it is easier to test these scripts,
# it will add the proper directories to the path so that 
# this script can be run from a checkout
if os.path.exists(os.path.join(os.path.dirname(os.path.dirname(__file__)),
                  'opengem')):
    sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

from opengem import flags
from opengem import logs

from opengem import jobber

from opengem.output import geotiff
from opengem.parser import exposure
from opengem.parser import vulnerability

FLAGS = flags.FLAGS

flags.DEFINE_string('exposure', 'exposure.xml', 'exposure input')
flags.DEFINE_string('vulnerability', 'vulnerability.xml',
                    'vulnerability input')
flags.DEFINE_string('filter_region', None, 'region to filter input')                    
flags.DEFINE_string('output_region', None, 'region to generate output')
flags.DEFINE_string('hazard_curves', 'hazard_curves.xml', 
                    'hazard curves')

flags.DEFINE_string('loss_map', 'loss_map.tiff', 'loss map output')
flags.DEFINE_string('loss_ratio_map', 'loss_ratio_map.tiff',
                    'loss ratio map output')

flags.DEFINE_boolean('profile', False, 'Run profiler?')
flags.DEFINE_boolean('load_profile', False, 'Load profiler data?')
flags.DEFINE_string('profile_log', 'gem-risk.profile', 'Profiling log')

flags.DEFINE_boolean('partition', False, 'Partition job?')

if __name__ == '__main__':
    args = FLAGS(sys.argv)
    logs.init_logs()
    
    # Collect inputs
    # Determine Processing type
    # Validate input data
    
    # Prepare final configuration, save it
    # Hash final config, store that
    
    # Kick off processing tasks, and wait...
    # Collate results
    # Generate output
    
    if FLAGS.profile:
        import cProfile
        cProfile.run('tasks.main(FLAGS.vulnerability, \
                        FLAGS.hazard_curves, FLAGS.region, \
                        FLAGS.exposure, FLAGS.loss_map)', FLAGS.profile_log)
    elif FLAGS.load_profile:
        import pstats
        p = pstats.Stats(FLAGS.profile_log)
        p.sort_stats('cumulative').print_stats(30)    
    else:
        #tasks.main(FLAGS.vulnerability, FLAGS.hazard_curves, FLAGS.filter_region, FLAGS.exposure, FLAGS.loss_map)

        the_jobber = jobber.Jobber(FLAGS.vulnerability, 
                                   FLAGS.hazard_curves, 
                                   FLAGS.filter_region, 
                                   FLAGS.exposure, 
                                   FLAGS.loss_map,
                                   FLAGS.partition)
        the_jobber.run()
