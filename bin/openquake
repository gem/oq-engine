#!/usr/bin/env python
# -*- coding: utf-8 -*-
# vim: tabstop=4 shiftwidth=4 softtabstop=4

"""Deterministic Risk Computations based on Hazard, Exposure and Vulnerability

Expects to receive:
    Shakemap (ground motion per grid cell)
    Exposure (value per grid cell)
    Vulnerability functions (multiple lists per grid cell)
    Region of interest

It can receive these either through gflags (current functionality), or
through a configuration file.

Expects to compute:
    A grid of loss-ratio curves and store the results in XML
    A grid of loss curves and store the results in XML 
    A map of losses at each interval and store the results in GeoTIFF

"""

import os
import sys

# this is a hack so that it is easier to test these scripts,
# it will add the proper directories to the path so that 
# this script can be run from a checkout
if os.path.exists(os.path.join(os.path.dirname(os.path.dirname(__file__)),
                  'openquake')):
    sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
    
from fabric.api import env, local, run
from multiprocessing import Process

from openquake import flags
from openquake import logs
from openquake import version as openquake_version

from openquake import job
from openquake.job import Job
from openquake.output import geotiff
from openquake.parser import exposure
from openquake.parser import vulnerability

from openquake.hazard import job as hazjob
from openquake.hazard import opensha
from openquake.risk import job as riskjob
from openquake.risk.job import probabilistic
from openquake.utils import version as utils_version

FLAGS = flags.FLAGS

flags.DEFINE_string('config_file', 'openquake-config.gem', 'OpenGEM configuration file')

flags.DEFINE_boolean('profile', False, 'Run profiler?')
flags.DEFINE_boolean('load_profile', False, 'Load profiler data?')
flags.DEFINE_string('profile_log', 'gem-risk.profile', 'Profiling log')

flags.DEFINE_boolean('partition', False, 'Partition job?')
flags.DEFINE_boolean('server', False, 'Launch redis-server and RabbitMQ subprocs')
flags.DEFINE_boolean('version', False, 'Show version information')
flags.DEFINE_boolean('worker', False, 'Launch celery subprocs')


def _launch_worker_subprocs():
    """Start celery as python subprocs.

    There should only be one copy of celery running.

    If a process is already running, don't kill it
    and carry on.

    If a process is not running, launch it as a
    multiprocessing.Process
    """
    # set the host string (otherwise, the user will be prompted for one)
    env.host_string = 'localhost'
    
    # launch celery if it's not already running
    if not _is_running('[c]elery'):
        print "Starting celery..."
        Process(target=local, args=('celeryd',)).start()


def _launch_server_subprocs():
    """Start redis-server and RabbitMQ as python subprocs.

    There should only be one copy of RabbitMQ running  
    and (for now) only one copy of redis-server.

    If a process is already running, don't kill it
    and carry on.

    If a process is not running, launch it as a
    multiprocessing.Process
    """
    # set the host string (otherwise, the user will be prompted for one)
    env.host_string = 'localhost'

    
    # launch rabbitmq if it's not already running
    if not _is_running('[r]abbitmq'):
        print "Starting rabbitmq..."
        Process(target=local, args=('sudo rabbitmq-server',)).start()

 
    # launch kvs if it's not already running
    if not _is_running('[r]edis-server'):
        print "Starting redis-server..."
        Process(target=local, args=('redis-server',)).start()


def _is_running(proc_name):
    """Checks to see if a process is already
    running by executing a 'ps aux | grep proc_name'.

    Be sure to surroud the first letter
    of the proc_name with [] to avoid getting
    a false positive from the grep
    (example: '[r]edis-server', instead of 'redis-server').
    """
    # set fabric to warn only (so fabric run() calls with no
    # response don't crash and burn)
    env.warn_only = True

    is_running = run('ps aux | grep %s' % proc_name) != ''
    # reset warn only
    env.warn_only = False

    return is_running


if __name__ == '__main__':
    args = FLAGS(sys.argv)

    if FLAGS.version:
        print utils_version.info(openquake_version)
        sys.exit(0)

    logs.init_logs()
    
    # Collect inputs
    # Determine Processing type
    # Validate input data
    
    # Prepare final configuration, save it
    # Hash final config, store that
    
    # Kick off processing tasks, and wait...
    # Collate results
    # Generate output
    
    if FLAGS.profile:
        import cProfile
        cProfile.run('tasks.main(FLAGS.vulnerability, \
                        FLAGS.hazard_curves, FLAGS.region, \
                        FLAGS.exposure, FLAGS.loss_map)', FLAGS.profile_log)
    elif FLAGS.load_profile:
        import pstats
        p = pstats.Stats(FLAGS.profile_log)
        p.sort_stats('cumulative').print_stats(30)    
    elif FLAGS.server:
        # launch redis and rabbitmq
        _launch_server_subprocs()
    elif FLAGS.worker:
        # launch celery
        _launch_worker_subprocs()
    else:
        job.run_job(FLAGS.config_file)
