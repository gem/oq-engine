package scratch.marco;

import java.util.ArrayList;
import java.util.HashMap;
import java.util.Map;

import org.opensha.commons.data.Site;
import org.opensha.commons.data.function.ArbitrarilyDiscretizedFunc;
import org.opensha.sha.earthquake.EqkRupForecastAPI;
import org.opensha.sha.earthquake.EqkRupture;
import org.opensha.sha.earthquake.ProbEqkRupture;
import org.opensha.sha.earthquake.ProbEqkSource;
import org.opensha.sha.imr.ScalarIntensityMeasureRelationshipAPI;
import org.opensha.sha.util.TRTUtils;
import org.opensha.sha.util.TectonicRegionType;

public class Fhcc {
	
	private static double MAXDISTANCE = 200.0;
	private static boolean INFO = false;
	private ArrayList<Site> siteArr;
	private Map<TectonicRegionType,ScalarIntensityMeasureRelationshipAPI> imrMap;
	private EqkRupForecastAPI eqkRupForecast;
	private ArrayList<Double> imlList;  // Currently not used

	/**
	 * 
	 * @param siteArr
	 * @param imrMap
	 * @param eqkRupForecast
	 */
	public Fhcc(
			ArrayList<Site> siteArr,
			Map<TectonicRegionType,ScalarIntensityMeasureRelationshipAPI> imrMap, 
			EqkRupForecastAPI eqkRupForecast) {	
		this.eqkRupForecast = eqkRupForecast;
		this.imrMap = imrMap;
		this.siteArr = siteArr;
		this.imlList = null;
	}
	
	/**
	 * 
	 * @return
	 */
	public HashMap<Integer,double[]> getMaps(){
		
		boolean flag = true;
		
		// Initializing the IMRs
		for (ScalarIntensityMeasureRelationshipAPI imr:imrMap.values()) {
			imr.resetParameterEventListeners();
			imr.setUserMaxDistance(MAXDISTANCE);
		}
		
		// Create an array where we store the pdf
		double gmMin = 0.0; double gmMax = 2.0; double gmWdt = 0.1;
		gmMin = Math.floor(gmMin/gmWdt)*gmWdt;
		gmMax = Math.floor(gmMax/gmWdt)*gmWdt;
		int numGm = (int) Math.round((gmMax-gmMin)/gmWdt);
		
		// This is an arraylist where we store the distinct hazard maps generated by all the sources
		// included in the PSHA input model
		HashMap<Integer,HashMap<Integer,double[]>> hazMaps = new HashMap<Integer,HashMap<Integer,double[]>>();
		
		// Loop on the sources contained in the ERF
		System.out.println("Looping on sources");
		for (int srcIdx=0; srcIdx < eqkRupForecast.getNumSources(); srcIdx++){
			
			// Get the source 
			ProbEqkSource source = eqkRupForecast.getSource(srcIdx);
			System.out.printf("   Source: %3d   # of ruptures: %6d\n",srcIdx,source.getNumRuptures());
			
			// Set the IMR according to the tectonic region of the source (if there is more than one)
			TectonicRegionType trt = source.getTectonicRegionType();
			ScalarIntensityMeasureRelationshipAPI imr = TRTUtils.getIMRForTRT(imrMap, trt);
			
			// Find the sites at a distance lower than the threshold distance
			ArrayList<Integer> siteIdxList = new ArrayList<Integer>();
			int cnt = 0;
			for (Site site: siteArr) {
				if (eqkRupForecast.getSource(srcIdx).getMinDistance(site) < MAXDISTANCE) {
					siteIdxList.add(cnt); 
				}
				cnt++;
			}
				
			// Find the number of sites of interests for the current source and their indexes
			// Initiate an hash map where we store the IMT probability mass function
			HashMap<Integer,double[]> imtPdfs = new HashMap<Integer,double[]>();
			
			// Loop on the locations where to calculate the hazard
			for (int siteIdx: siteIdxList){
				
				// Set the site 
				imr.setSite(siteArr.get(siteIdx));
			
				// Rupture list for the current source
				ArrayList<EqkRupture> rupList = source.getRuptureList();
				
				// Create an arbitrarily discretized func to calculate the 
				ArbitrarilyDiscretizedFunc srcHazFun = new ArbitrarilyDiscretizedFunc();
				for (int gmIdx = 0; gmIdx < numGm+1; gmIdx++) {
					srcHazFun.set(gmMin+gmIdx*gmWdt, 0.0);
				}
				
				// Loop on the ruptures 
				for (EqkRupture rupture: rupList){

					SiteRuptureDistanceCalculator sdCalc = 
						new SiteRuptureDistanceCalculator(siteArr.get(siteIdx),rupture);
					
					// Get the distance between the site and the rupture 
					double dst01 = sdCalc.getJBDistance();
					
					if (dst01 < MAXDISTANCE){
					
						// Set the EqkRup in the IMR
						imr.setEqkRupture(rupture);
						
						// Get the rupture probability
						double qkProb = ((ProbEqkRupture) rupture).getProbability();
	
						// Create an Arbitrarily Discretized Func
						ArbitrarilyDiscretizedFunc arbFun = new ArbitrarilyDiscretizedFunc();
						for (int gmIdx = 0; gmIdx < numGm+1; gmIdx++) {
							arbFun.set(gmMin+gmIdx*gmWdt, 0.0);
						}
							
						// Set the EqkRup in the IMR
						imr.setEqkRupture(rupture);
	
						// Get the conditional probability of exceedance from the IMR
						arbFun = (ArbitrarilyDiscretizedFunc) imr.getExceedProbabilities(arbFun);
						
//						if (flag){
//							for(int j=0; j<arbFun.getNum();j++){
//								System.out.printf(" gm %5.2e pex %5.2e \n",arbFun.getX(j),arbFun.getY(j));
//							}
//							flag = false;
//						}
						
						// Update the source hazard function
						for (int j=0; j < arbFun.getNum(); j++){
							srcHazFun.set(j,srcHazFun.getY(j) + qkProb*arbFun.getY(j));
						}
					}
					
				} // end of rupture loop
				
				// Update the source hazard function
				double[] pmf = new double[numGm];
				for (int k=0; k<srcHazFun.getNum();k++){
					srcHazFun.set(k,srcHazFun.getY(k)*(1-srcHazFun.getY(k)));
					// Calculate the pmf
					if (k > 0){
						pmf[k-1] = srcHazFun.getY(k-1)-srcHazFun.getY(k);
					}
				}
				
				// Store the PMF
				imtPdfs.put(siteIdx,pmf);
				
			} // end of site loop
			
			// Update the hazard map array list
			hazMaps.put(srcIdx, imtPdfs);
			
		} // end of source loop
		
		// Now I calculate the final hazard curve array by convolving the hazard maps obtained for each 
		// seismic source contained in the model
		System.out.println("Computing hazard curves");
		HashMap<Integer,double[]> hazCurvesList 	= new HashMap<Integer,double[]>();
		HashMap<Integer,Integer> hazCurvesCounter 	= new HashMap<Integer,Integer>();
		for (int srcIdx=0; srcIdx < eqkRupForecast.getNumSources(); srcIdx++){
			System.out.printf("   Source: %3d\n",srcIdx);
			for (int siteIdx=0; siteIdx < siteArr.size(); siteIdx++){
				if (hazMaps.get(srcIdx).containsKey(siteIdx)){
					if (hazCurvesCounter.get(siteIdx) != null){
						// Update the PMF for one site
						hazCurvesCounter.put(siteIdx,hazCurvesCounter.get(siteIdx)+1);
						hazCurvesList.put( siteIdx,convolvePMF(
								hazMaps.get(srcIdx).get(siteIdx),
								hazCurvesList.get(siteIdx)) );
					} else {
						// Initalize
						hazCurvesList.put(siteIdx,hazMaps.get(srcIdx).get(siteIdx));
						hazCurvesCounter.put(siteIdx,1);
					}
				}
			}
		}
		
		return hazCurvesList;
	}
	
//	public static void main(String[] args) {
//		System.out.println("Testing convolution");
//		double[] A = {1,2,3,4,5};
//		double[] B = {5,6,7};
//		double[] xx = convolvePMF(A,B);
//	}
	
	/**
	 * Convolution routine
	 * @return
	 */
	private static double[] convolvePMF(double[] pmfA, double[] pmfB){
		boolean PRB = true;
		double[] X, Y;
		int idx, idxX, idxY;
		
		int totLen = pmfA.length+pmfB.length;
		double[] pmfOut = new double[totLen];
		if (INFO) System.out.println("Output array size: "+totLen);
		
		if (pmfA.length < pmfB.length) {
			X = new double[pmfB.length+1];
			Y = new double[pmfA.length+1];
			if (PRB) {
				double sum = 0.0;
				for (int i=0; i<pmfB.length-1; i++){
					X[i+1] = pmfB[i];
					sum = sum + pmfB[i];
				}
				X[0] = 1.0 - sum;
				for (int i=0; i<pmfA.length-1; i++){
					Y[i+1] = pmfA[i];
					sum = sum + pmfA[i];
				}
				Y[0] = 1.0 - sum;
			} else {
				X = pmfB;
				Y = pmfA;
			}
		} else {
			Y = new double[pmfB.length];
			X = new double[pmfA.length]; 
			if (PRB) {
				double sum = 0.0;
				for (int i=0; i<pmfA.length-1; i++){
					X[i+1] = pmfA[i];
					sum = sum + pmfA[i];
				}
				X[0] = 1.0 - sum;
				for (int i=0; i<pmfB.length-1; i++){
					Y[i+1] = pmfB[i];
					sum = sum + pmfB[i];
				}
				Y[0] = 1.0 - sum;
			} else {
				X = pmfA;
				Y = pmfB;
			}
		}
		Y = reverseArray(Y);

		for (int i=0; i < totLen; i++){
			if (INFO) System.out.printf("------- i: %3d  \n",i);
			if (i < Y.length-1){
				for (int j=0; j <= i; j++){
					idxY = Y.length-j-1;
					idxX = i - j;
					if (INFO) System.out.println("A:"+i+" "+j+" "+idxY);
					pmfOut[i] = pmfOut[i] + X[idxX] * Y[idxY];
					if (INFO) System.out.println(X[idxX]+" * "+Y[idxY]);
				}
				if (INFO) System.out.println(pmfOut[i]);
			} else if (i >= totLen-Y.length){
				for (int j=0; j < (totLen-i); j++){
					idxX = (X.length-totLen+i)+j;
					idxY = j;
					if (INFO) System.out.println("C:"+i+" idxX "+idxX+" idxY "+idxY);
					pmfOut[i] = pmfOut[i] + X[idxX] * Y[idxY];
					if (INFO) System.out.println(X[idxX]+" * "+Y[idxY]);
				}		
				if (INFO) System.out.println(">>"+pmfOut[i]);
			} else {
				for (int j=0; j < Y.length; j++){
					idxX = (i-Y.length+1) + j;
					idxY = j;
					if (INFO) System.out.println("C:"+i+" idxX "+idxX+" idxY "+idxY);
					pmfOut[i] = pmfOut[i] + X[idxX] * Y[idxY];
					if (INFO) System.out.println(X[idxX]+" * "+Y[idxY]);
				}
				if (INFO) System.out.println(">>"+pmfOut[i]);
			}
		}
		if (INFO) for (int i=0; i <pmfOut.length; i++) System.out.println(pmfOut[i]);
		return pmfOut; 
	}
	
//	/**
//	 * Convolution routine
//	 * @return
//	 */
//	private static double[] convolveUnevenlyPMF(double[] pmfA, double[] pmfB){
//		boolean PRB = true;
//		double[] X, Y;
//		double[] wX, wY;
//		int idx, idxX, idxY;
//		
//		int totLen = pmfA.length+pmfB.length;
//		double[] pmfOut = new double[totLen];
//		if (INFO) System.out.println("Output array size: "+totLen);
//		
//		if (pmfA.length < pmfB.length) {
//			X = new double[pmfB.length+1];
//			Y = new double[pmfA.length+1];
//			if (PRB) {
//				double sum = 0.0;
//				for (int i=0; i<pmfB.length-1; i++){
//					X[i+1] = pmfB[i];
//					sum = sum + pmfB[i];
//				}
//				X[0] = 1.0 - sum;
//				for (int i=0; i<pmfA.length-1; i++){
//					Y[i+1] = pmfA[i];
//					sum = sum + pmfA[i];
//				}
//				Y[0] = 1.0 - sum;
//				
//			} else {
//				X = pmfB;
//				Y = pmfA;
//			}
//		} else {
//			Y = new double[pmfB.length];
//			X = new double[pmfA.length]; 
//			if (PRB) {
//				double sum = 0.0;
//				for (int i=0; i<pmfA.length-1; i++){
//					X[i+1] = pmfA[i];
//					sum = sum + pmfA[i];
//				}
//				X[0] = 1.0 - sum;
//				for (int i=0; i<pmfB.length-1; i++){
//					Y[i+1] = pmfB[i];
//					sum = sum + pmfB[i];
//				}
//				Y[0] = 1.0 - sum;
//			} else {
//				X = pmfA;
//				Y = pmfB;
//			}
//		}
//		Y = reverseArray(Y);
//
//		for (int i=0; i < totLen; i++){
//			if (INFO) System.out.printf("------- i: %3d  \n",i);
//			if (i < Y.length-1){
//				for (int j=0; j <= i; j++){
//					idxY = Y.length-j-1;
//					idxX = i - j;
//					if (INFO) System.out.println("A:"+i+" "+j+" "+idxY);
//					pmfOut[i] = pmfOut[i] + X[idxX] * Y[idxY];
//					if (INFO) System.out.println(X[idxX]+" * "+Y[idxY]);
//				}
//				if (INFO) System.out.println(pmfOut[i]);
//			} else if (i >= totLen-Y.length){
//				for (int j=0; j < (totLen-i); j++){
//					idxX = (X.length-totLen+i)+j;
//					idxY = j;
//					if (INFO) System.out.println("C:"+i+" idxX "+idxX+" idxY "+idxY);
//					pmfOut[i] = pmfOut[i] + X[idxX] * Y[idxY];
//					if (INFO) System.out.println(X[idxX]+" * "+Y[idxY]);
//				}		
//				if (INFO) System.out.println(">>"+pmfOut[i]);
//			} else {
//				for (int j=0; j < Y.length; j++){
//					idxX = (i-Y.length+1) + j;
//					idxY = j;
//					if (INFO) System.out.println("C:"+i+" idxX "+idxX+" idxY "+idxY);
//					pmfOut[i] = pmfOut[i] + X[idxX] * Y[idxY];
//					if (INFO) System.out.println(X[idxX]+" * "+Y[idxY]);
//				}
//				if (INFO) System.out.println(">>"+pmfOut[i]);
//			}
//		}
//		if (INFO) for (int i=0; i <pmfOut.length; i++) System.out.println(pmfOut[i]);
//		return pmfOut; 
//	}
	
	/**
	 * 
	 * @param arr
	 * @return
	 */
	private static double[] reverseArray(double[] arr){
		double[] rev = new double[arr.length];
		for (int i=0; i<arr.length; i++){
			rev[i] = arr[arr.length-1-i];
		}
		return rev;
	}
}
